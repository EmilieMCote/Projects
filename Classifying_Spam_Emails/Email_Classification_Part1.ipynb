{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ea61da",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "\n",
    "<h1 style=\"text-align: center;\">Spam/Ham Classification Part 1 $\\rightarrow$ E.D.A. & Feature Engineering</h1>\n",
    "\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec89286",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "**Goal**: Create a binary classifier that can distinguish spam (junk, commercial, or bulk) emails from ham (regular non-spam) emails.\n",
    "\n",
    "Part 1 includes the following:\n",
    "\n",
    "- Feature engineering with text data.\n",
    "- Using the `sklearn` library to process data and fit models.\n",
    "- Validating the performance of our model and minimizing overfitting.\n",
    "\n",
    "This Part 1, focuses on initial data analysis, feature engineering, and logistic regression.   \n",
    "Part 2 of this project, I build a spam/ham classifier.  \n",
    "\n",
    "***Warning*** This is a **real-world** dataset so the emails are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04813e03",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150c1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9317b7",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "\n",
    "# The Data\n",
    "\n",
    "In email classification, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. The dataset is from [SpamAssassin](https://spamassassin.apache.org/old/publiccorpus/). It consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8,348 labeled examples, and the unlabeled test set contains 1,000 unlabeled examples.\n",
    "\n",
    "**Note:** The dataset is from 2004, so the contents of emails might be very different from those in 2024.\n",
    "\n",
    "Run the following cells to load the data into a `DataFrame`.\n",
    "\n",
    "The `train` `DataFrame` contains labeled data you will use to train your model. It has four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example.\n",
    "1. `subject`: The subject of the email.\n",
    "1. `email`: The text of the email.\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam).\n",
    "\n",
    "The `test` `DataFrame` contains 1,000 unlabeled emails. In Project B2, you will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6c5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Loading training and test datasets\n",
    "with zipfile.ZipFile('../spam_ham_data.zip') as item:\n",
    "    with item.open(\"train.csv\") as f:\n",
    "        original_training_data = pd.read_csv(f)\n",
    "    with item.open(\"test.csv\") as f:\n",
    "        test = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa5ae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...     0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...     1  \n",
       "3  depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the emails to lowercase as the first step of text processing.\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a3b9d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "First, let's check if our data contains any missing values. We have filled in the cell below to print the number of `NaN` values in each column. If there are `NaN` values, we replace them with appropriate filler values (i.e., `NaN` values in the `subject` or `email` columns will be replaced with empty strings). Finally, we print the number of `NaN` values in each column after this modification to verify that there are no `NaN` values left.\n",
    "\n",
    "**Note:** While there are no `NaN` values in the `spam` column, we should be careful when replacing `NaN` labels. Doing so without consideration may introduce significant bias into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aeb5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "id         0\n",
      "subject    6\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n",
      "------------\n",
      "After imputation:\n",
      "id         0\n",
      "subject    0\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Before imputation:')\n",
    "print(original_training_data.isnull().sum())\n",
    "original_training_data = original_training_data.fillna('')\n",
    "print('------------')\n",
    "print('After imputation:')\n",
    "print(original_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fede2",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "\n",
    "# Part 1: Initial Analysis\n",
    "\n",
    "In the cell below, we have printed the text of the `email` field for the first ham and the first spam email in the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a459a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham Email:\n",
      "url: http://boingboing.net/#85534171\n",
      " date: not supplied\n",
      " \n",
      " arts and letters daily, a wonderful and dense blog, has folded up its tent due \n",
      " to the bankruptcy of its parent company. a&l daily will be auctioned off by the \n",
      " receivers. link[1] discuss[2] (_thanks, misha!_)\n",
      " \n",
      " [1] http://www.aldaily.com/\n",
      " [2] http://www.quicktopic.com/boing/h/zlfterjnd6jf\n",
      " \n",
      " \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Spam Email:\n",
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      " <font size=3d\"4\"><b> a man endowed with a 7-8\" hammer is simply<br>\n",
      "  better equipped than a man with a 5-6\"hammer. <br>\n",
      " <br>would you rather have<br>more than enough to get the job done or fall =\n",
      " short. it's totally up<br>to you. our methods are guaranteed to increase y=\n",
      " our size by 1-3\"<br> <a href=3d\"http://209.163.187.47/cgi-bin/index.php?10=\n",
      " 004\">come in here and see how</a>\n",
      " </body>\n",
      " </html>\n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0]\n",
    "first_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0]\n",
    "print(\"Ham Email:\")\n",
    "print(first_ham)\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"Spam Email:\")\n",
    "print(first_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb918c2",
   "metadata": {},
   "source": [
    "## Training-Validation Split\n",
    "The training data we downloaded is all the data we have available for both training models and **validating** the models that we train. We, therefore, need to split the training data into separate training and validation datasets. You will need this **validation data** to assess the performance of your classifier once you are finished training. Note that we set the seed (`random_state`) to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d6c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size = 0.1,\n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3687ba0",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "\n",
    "# Part 2: Feature Engineering\n",
    "\n",
    "We want to take the text of an email and predict whether the email is ham or spam. This is a **binary classification** problem, so we can use logistic regression to train a classifier. Recall that to train a logistic regression model, we need a numeric feature matrix $\\mathbb{X}$ and a vector of corresponding binary labels $Y$. Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "Each row of $\\mathbb{X}$ is an email. Each column of $\\mathbb{X}$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efaabb3",
   "metadata": {},
   "source": [
    "\n",
    "## 2.a\n",
    "\n",
    "Create a function `words_in_texts` that takes in a list of interesting words (`words`) and a `Series` of emails (`texts`). Our goal is to check if each word in `words` is contained in the emails in `texts`.\n",
    "\n",
    "The `words_in_texts` function should output a **2-dimensional `NumPy` array** that contains one row for each email in `texts` and one column for each word in `words`. If the $j$-th word in `words` is present at least once in the $i$-th email in `texts`, the output array should have a value of 1 at the position $(i, j)$. Otherwise, if the $j$-th word is not present in the $i$-th email, the value at $(i, j)$ should be 0.\n",
    "\n",
    "In Project B2, we will be applying `words_in_texts` to some large datasets, so implementing some form of vectorization (for example, using `NumPy` arrays, `Series.str` functions, etc.) is highly recommended. **You are allowed to use only *one* list comprehension or for loop**, and you should look into how you could combine that with the vectorized functions discussed above. **Do not use a double for loop, or you will run into issues later on in Project B2.**\n",
    "\n",
    "For example:\n",
    "```\n",
    ">>> words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))\n",
    "\n",
    "array([[1, 0, 0],\n",
    "       [1, 0, 1]])\n",
    "```\n",
    "\n",
    "Importantly, we **do not** calculate the *number of occurrences* of each word; only if the word is present at least *once*. Take a moment to work through the example on your own if need be —— understanding what the function does is a critical first step in implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e112a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words (list): Words to find.\n",
    "        texts (Series): Strings to search in.\n",
    "    \n",
    "    Returns:\n",
    "        A 2D NumPy array of 0s and 1s with shape (n, d) where \n",
    "        n is the number of texts, and d is the number of words.\n",
    "    \"\"\"\n",
    "    indicator_array = np.array([texts.str.contains(word).astype(int) for word in words]).T\n",
    "    return indicator_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbf255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to see what your function outputs. Compare the results to the example provided above.\n",
    "words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d76e6",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "\n",
    "# Part 3: EDA\n",
    "\n",
    "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. Suppose the feature is a binary indicator, such as whether a particular word occurs in the text. In that case, this compares the proportion of spam emails with the word to the proportion of ham emails with the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91555ed5",
   "metadata": {},
   "source": [
    "The following plot (created using `sns.barplot`) compares the proportion of emails in each class containing a particular set of words. The bars colored by email class were generated by setting the `hue` parameter of `sns.barplot` to a column containing the class (spam or ham) of each data point. An example of how this class column was created is shown below:\n",
    "\n",
    "![training conditional proportions](./images/training_conditional_proportions.png)\n",
    "\n",
    "You can use `DataFrame`'s `.melt` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)) method to \"unpivot\" a `DataFrame`. See the following code cell for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1097f",
   "metadata": {},
   "source": [
    "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous Step). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cb07c",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid hsl(200, 100%, 50%);\" />   <!-- bright blue -->\n",
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "\n",
    "\n",
    "# Part 4: Basic Classification\n",
    "\n",
    "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53e2ac",
   "metadata": {},
   "source": [
    "Using 5 words that might be useful as features differentiating spam from ham emails and the `train` `DataFrame`, we create two `NumPy` arrays: `X_train` and `Y_train`. `X_train` should be a 2D array of 0s and 1s created using the `words_in_texts` function on all the emails in the training set. `Y_train` should be a vector of the correct labels for each email in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f931c13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = train['spam'].to_numpy()\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc46ba",
   "metadata": {},
   "source": [
    "\n",
    "## 4.a\n",
    "\n",
    "Now that we have matrices, we can build a model with `sklearn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.76$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24541908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_model = LogisticRegression()\n",
    "my_model.fit(X_train, Y_train)\n",
    "Y_pred = my_model.predict(X_train)\n",
    "\n",
    "# using built-in function\n",
    "score = accuracy_score(Y_train,Y_pred)\n",
    "\n",
    "# using definition of accuracy\n",
    "training_accuracy = np.mean(Y_pred == Y_train)\n",
    "\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189466a7",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />\n",
    "<hr style=\"border: 5px solid hsl(200, 100%, 50%);\" />   <!-- bright blue -->\n",
    "\n",
    "# Part 5: Evaluating Classifiers  \n",
    "\n",
    "That doesn't seem too shabby! But the classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating the accuracy of the model on the training set, which may be a misleading measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will make use of the data we held out for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, or preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- **False positive (FP)**: A ham email gets flagged as spam and filtered out of the inbox.\n",
    "- **False negative (FN)**: A spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier in addition to overall accuracy:\n",
    "\n",
    "**Precision**: Measures the proportion of emails flagged as spam that are actually spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$.\n",
    "\n",
    "**Recall**: Measures the proportion  of spam emails that were correctly flagged as spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$.\n",
    "\n",
    "**False positive rate**: Measures the proportion  of ham emails that were incorrectly flagged as spam. Mathematically, $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$.\n",
    "\n",
    "One quick mnemonic to remember the formulas is that **P**recision involves T**P** and F**P**, Recall does not. In the final, the reference sheet will also contain the formulas shown above, but you should be able to interpret what they mean and their importance depending on the context.\n",
    "\n",
    "The below graphic (modified slightly from [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)) may help you understand precision and recall visually:<br />\n",
    "<center>\n",
    "<img alt=\"precision_recall\" src=\"./images/precision_recall.png\" width=\"600px\" />\n",
    "</center>\n",
    "\n",
    "Note that a True Positive (TP) is a spam email that is classified as spam, and a True Negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe03fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5.a\n",
    "\n",
    "Suppose we have a hypothetical classifier called the “zero predictor.” For any inputted email, the zero predictor *always* predicts 0 (it never makes a prediction of 1 for any email). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Assign `zero_predictor_fp` to the number of false positives and `zero_predictor_fn` to the number of false negatives for the hypothetical zero predictor on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dc4fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1918)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_zero_pred = np.zeros(train.shape[0])\n",
    "\n",
    "# predicted as 1 but actually 0, but zero predictor always zero -- NO FALSE Positives\n",
    "zero_predictor_fp = 0\n",
    "zero_predictor_fn = sum(Y_zero_pred != Y_train)\n",
    "zero_predictor_fp, zero_predictor_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f384605",
   "metadata": {},
   "source": [
    "\n",
    "## 5.b\n",
    "\n",
    "What is the accuracy and recall of the zero predictor on the training data? Don't need to use any `sklearn` functions to compute these performance metrics, but they are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d786ef0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7447091707706642, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_zero_pred = np.zeros(train.shape[0])\n",
    "True_pos = 0\n",
    "zero_predictor_acc = np.mean(Y_zero_pred == Y_train)\n",
    "zero_predictor_recall = True_pos / (True_pos + zero_predictor_fn)\n",
    "zero_predictor_acc, zero_predictor_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03a19a",
   "metadata": {},
   "source": [
    "\n",
    "## 5.c\n",
    "\n",
    "Explain your results in `q6a` and `q6b`. How did you know what to assign to `zero_predictor_fp`, `zero_predictor_fn`, `zero_predictor_acc`, and `zero_predictor_recall`?\n",
    "\n",
    "### For 5.a:  \n",
    "\n",
    "1.\tY_zero_pred = np.zeros(train.shape[0]):  \n",
    "\t•\tThis creates a prediction array of all zeros (i.e., all emails are predicted as ham). Perfect for the zero predictor.  \n",
    "\n",
    "2.\tzero_predictor_fp = 0:  \n",
    "\t•\tSince the zero predictor always predicts 0 (ham), there can be no false positives (no ham email is incorrectly flagged as spam).  \n",
    "\n",
    "3.\tzero_predictor_fn = sum(Y_zero_pred != Y_train):  \n",
    "\t•\tThis counts all cases where the true label (Y_train) is 1 (spam), but the prediction is 0 (ham). In this case, it’s equal to the total number of spam emails because all are misclassified as ham by the zero predictor.\n",
    "\n",
    "4.\tOutput zero_predictor_fp, zero_predictor_fn = (0, 1918):  \n",
    "\t•\tFP = 0 (logic explained in 2.)  \n",
    "\t•\tFN = 1918: must be right, as there are 1918 spam emails that the zero predictor fails to classify correctly.   \n",
    "\n",
    "\n",
    "### For 5.b:\n",
    "\n",
    "1.\tY_zero_pred = np.zeros(train.shape[0]):  \n",
    "\t•\tThis generates an array of zeros (predicting all emails as ham), which aligns with the behavior of a zero predictor.  \n",
    "\n",
    "2.\tTrue Positives (True_pos):  \n",
    "\t•\tThis must be set to 0 because the zero predictor never predicts 1 (spam).  \n",
    "\n",
    "3.\tAccuracy (zero_predictor_acc):  \n",
    "\t•\tnp.mean(Y_zero_pred == Y_train):  \n",
    "\t•\tThis calculates the proportion of emails that the zero predictor classified correctly.  \n",
    "\t•\tIt includes all true negatives (ham emails correctly classified as ham) divided by the total number of emails.  \n",
    "\n",
    "4.\tRecall (zero_predictor_recall):  \n",
    " \t•\tTrue_pos / (True_pos + zero_predictor_fn):   \n",
    "\t•\tSince True_pos = 0, recall will also be 0 due to the formula: $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$  \n",
    "\t•\tThis reflects the zero predictor’s inability to identify any spam emails.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29b55e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5.d\n",
    "\n",
    "Compute the precision, recall, and false positive rate of the `LogisticRegression` classifier `my_model` from 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03fc333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=219, TN=5473, FP=122, FN=1699\n",
      "\n",
      "logistic_predictor_precision=0.64 \n",
      "logistic_predictor_recall=0.04 \n",
      "logistic_predictor_fpr=0.02\n"
     ]
    }
   ],
   "source": [
    "Y_train_hat =  my_model.predict(X_train)\n",
    "\n",
    "TP = sum((Y_train_hat == 1) & (Y_train == 1))\n",
    "TN = sum((Y_train_hat == 0) & (Y_train == 0))\n",
    "FP = sum((Y_train_hat == 1) & (Y_train == 0))\n",
    "FN = sum((Y_train_hat == 0) & (Y_train == 1))\n",
    "logistic_predictor_precision = TP/(FP+TP)\n",
    "logistic_predictor_recall = TP/(FP+TN)\n",
    "logistic_predictor_fpr = FP/(FP+TN)\n",
    "\n",
    "print(f\"{TP=}, {TN=}, {FP=}, {FN=}\\n\")\n",
    "print(f\"{logistic_predictor_precision=:.2f} \\n{logistic_predictor_recall=:.2f}\",\n",
    "      f\"\\n{logistic_predictor_fpr=:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df5901",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5.e\n",
    "\n",
    "Is the number of false positives produced by the logistic regression classifier `my_model` strictly greater than the number of false negatives produced? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8f01aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Answer = False\n",
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20e802",
   "metadata": {},
   "source": [
    "#### For the logistic regression classifier `my_model`:\n",
    "$FN \\gt \\gt FP$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ea5fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5.f\n",
    "\n",
    "How does the accuracy of the logistic regression classifier `my_model` compare to the accuracy of the zero predictor?\n",
    "\n",
    "\n",
    "The accuracy of the logistic regression classifier my_model was 0.7576 which is slightly higher (but not significantly) than the accuracy of the zero predictor of 0.7447. However, this small improvement is marginal, and recall of 0.04 for the logistic regression classifier is also not much better than recall of 0 for the zero predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297a6fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5.g\n",
    "\n",
    "Given the word features provided in Step 4, discuss why the logistic regression classifier `my_model` may be performing poorly.   \n",
    "\n",
    "\n",
    "\n",
    "The logistic regression classifier may be performing poorly for the following reasons:  \n",
    "1.\tWord Prevalence and Imbalance:  \n",
    "\t•\tIf the words used as features are not strongly indicative of spam or ham emails, the classifier may struggle to distinguish between the two classes. For example, some words might occur frequently in both spam and ham emails, making them less useful for classification.  \n",
    "2.\tSparse or Non-discriminative Features:  \n",
    "\t•\tLogistic regression heavily relies on the features being discriminative. If the word features provided are sparse (rarely occur) or appear in both classes (spam and ham) with similar frequencies, the model will fail to learn meaningful distinctions.  \n",
    "3.\tClass Imbalance:  \n",
    "    •\tIn our dataset, spam emails are outnumbered by ham emails, so the model may be biased toward predicting the majority class (ham) to achieve a higher accuracy, resulting in poor recall for spam detection.  \n",
    "4.\tFeature Representation:  \n",
    "    •\tThe words may not fully capture the nuanced patterns in the data. For instance, logistic regression may not handle cases where spam detection requires understanding word combinations, positions, or semantics, as it treats each word independently.  \n",
    "5.\tOverfitting to Training Data:  \n",
    "\t•\tIf the features are too specific or not generalized enough (e.g., certain words only appear in a small subset of the data), the model might overfit to these patterns and perform poorly on unseen data.  \n",
    "\n",
    "Possible Ways to Improve Performance:  \n",
    "\n",
    "1.\tUse Additional Features:  \n",
    "\t•\tConsider adding features like word combinations (n-grams), email metadata, or word frequencies to improve discriminative power.  \n",
    "2.\tHandle Class Imbalance:  \n",
    "\t•\tUse techniques like oversampling the minority class (spam) or applying class weights in logistic regression to balance the importance of spam and ham classifications.  \n",
    "3.\tFeature Selection:  \n",
    "\t•\tEvaluate the usefulness of each word feature and remove those that are not strongly correlated with spam or ham.   \n",
    "\n",
    "The model’s performance indicates that the provided features may not be sufficiently informative for the spam classification task.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6da0cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5.h\n",
    "\n",
    "Would you prefer to use the logistic regression classifier `my_model` or the zero predictor classifier for a spam filter? Why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "I would prefer to use the logistic regression classifier (my_model) over the zero predictor for a spam filter, despite the logistic regression model’s poor recall. Here’s why:\n",
    " \n",
    "1.\tZero Predictor Recall = 0:  \n",
    "   •\tThe zero predictor has zero recall, meaning it fails to identify any spam emails. This is unacceptable for a spam filter, as the primary goal is to catch as many spam emails as possible.  \n",
    "2.\tLogistic Regression Recall = 4%:  \n",
    "\t•\tWhile the recall for my_model is low (4%), it is still better than the zero predictor’s recall (0%). The logistic regression model can at least identify some spam emails.  \n",
    "3.\tImproved Precision:  \n",
    "\t•\tThe logistic regression model achieves a precision of 64%, meaning that when it predicts an email as spam, it is correct 64% of the time. This is a reasonable starting point for spam detection.  \n",
    "4.\tZero Predictor Fails to Act as a Filter:  \n",
    "\t•\tThe zero predictor would classify all emails as ham, allowing spam emails to flood the inbox. This completely undermines the purpose of a spam filter.  \n",
    "\n",
    "That said, while using the logistic regression classifier, I would try to implement some of the improvements I described in q6g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11320b09",
   "metadata": {},
   "source": [
    "**In Part 2**, we'll focus on using logistic regression to build a spam/ham email classifier. Now that we have considered what the data looks like, how it can be used, and engineered some useful features, predicative of our target classes, we can transition to building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda545c",
   "metadata": {},
   "source": [
    "<hr style=\"border: 4.5px solid teal;\" />\n",
    "<hr style=\"border: 3.3px solid #10b981;\" />   <!-- Emerald -->\n",
    "<hr style=\"border: 2.2px solid teal;\" />\n",
    "<hr style=\"border: 2px solid cornflowerblue;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
